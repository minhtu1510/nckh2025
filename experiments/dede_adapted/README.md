# DeDe-Adapted: Encoder-Decoder cho Network Traffic

## ğŸ¯ Ã tÆ°á»Ÿng

**DeDe (Original - CVPR 2025):**
- PhÃ¡t hiá»‡n backdoor samples trong SSL encoders cho **dá»¯ liá»‡u áº£nh**
- Sá»­ dá»¥ng **Vision Transformer** + Masked Autoencoder
- Mask random **patches** vÃ  reconstruct

**DeDe-Adapted (Cáº£i tiáº¿n cho Network Data):**
- PhÃ¡t hiá»‡n **adversarial samples** trong IDS cho **dá»¯ liá»‡u máº¡ng**
- Sá»­ dá»¥ng **MLP** + Masked Autoencoder  
- Mask random **features** vÃ  reconstruct
- DÃ¹ng reconstruction error Ä‘á»ƒ detect adversarial samples

---

## ğŸ—ï¸ Kiáº¿n trÃºc

### **So sÃ¡nh vá»›i DeDe gá»‘c:**

| Component | DeDe (Original) | DeDe-Adapted |
|-----------|----------------|--------------|
| **Input** | Images (224Ã—224Ã—3) | Tabular features (~77 dims) |
| **Encoder** | Vision Transformer (ViT) | MLP (256â†’128â†’64) |
| **Masking** | Random patches (75%) | Random features (50%) |
| **Decoder** | Transformer Decoder | MLP (128â†’256â†’77) |
| **Loss** | MSE on masked patches | MSE on masked features |
| **Detection** | Reconstruction error | Reconstruction error |

### **Architecture Diagram:**

```
Input Features (77 dims)
         â†“
    MASKING (50%)
    [mask random features]
         â†“
    ENCODER (MLP)
    [256 â†’ 128 â†’ 64]
         â†“
  Latent Representation (64 dims)
         â†“
    DECODER (MLP)
    [128 â†’ 256 â†’ 77]
         â†“
Reconstructed Features (77 dims)
         â†“
 Reconstruction Error
 (MSE per sample)
         â†“
    DETECTION
[High error = Adversarial]
```

---

## ğŸ“Š CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng

### **Training (trÃªn clean data):**

1. **Load clean data** tá»« Exp1 (baseline)
2. **Mask 50% features** ngáº«u nhiÃªn
3. **Encode** â†’ latent representation
4. **Decode** â†’ reconstruct original features
5. **Minimize MSE** trÃªn masked features
6. Model há»c **pattern of normal network traffic**

### **Detection (trÃªn test data):**

1. **Forward pass** qua encoder-decoder (khÃ´ng mask)
2. **Calculate reconstruction error** (MSE)
3. **Clean samples**: Low reconstruction error (model biáº¿t reconstruct)
4. **Adversarial samples**: High reconstruction error (out-of-distribution)
5. **Threshold**: Sá»­ dá»¥ng 95th percentile cá»§a clean errors

```python
threshold = np.percentile(clean_errors, 95)
is_adversarial = (error > threshold)
```

---

## ğŸš€ CÃ¡ch cháº¡y

### **Step 1: Train DeDe-Adapted model**

Train trÃªn clean data (Exp1 baseline):

```bash
python experiments/dede_adapted/train_dede.py \
    --data-dir datasets/splits/raw_scaled/exp1_baseline \
    --output-dir experiments/dede_adapted/models \
    --epochs 100 \
    --batch-size 128 \
    --mask-ratio 0.5 \
    --latent-dim 64 \
    --learning-rate 0.001
```

**Parameters:**
- `--mask-ratio`: Tá»· lá»‡ features bá»‹ mask (0.5 = 50%)
- `--latent-dim`: KÃ­ch thÆ°á»›c latent space
- `--epochs`: Sá»‘ epochs training

**Output:**
```
experiments/dede_adapted/models/
â”œâ”€â”€ best_model.h5              # Best model (validation loss)
â”œâ”€â”€ dede_final.h5              # Final model
â”œâ”€â”€ training_history.png       # Loss curves
â”œâ”€â”€ training_config.json       # Hyperparameters
â””â”€â”€ model_architecture.txt     # Model summary
```

---

### **Step 2: Detect adversarial samples**

Test trÃªn adversarial data (Exp3 GAN attack):

```bash
python experiments/dede_adapted/detect_adversarial.py \
    --model-dir experiments/dede_adapted/models \
    --clean-data datasets/splits/raw_scaled/exp1_baseline \
    --adv-data datasets/splits/raw_scaled/exp3_gan_attack \
    --output-dir experiments/dede_adapted/results \
    --threshold-percentile 95
```

**Parameters:**
- `--threshold-percentile`: Percentile cá»§a clean errors lÃ m threshold (95 = 5% FPR)

**Output:**
```
experiments/dede_adapted/results/
â”œâ”€â”€ detection_results.json      # Detailed results
â”œâ”€â”€ detection_summary.csv       # Summary metrics
â”œâ”€â”€ error_distributions.png     # Error histograms
â”œâ”€â”€ roc_curve.png               # ROC curve
â””â”€â”€ confusion_matrix.png        # Confusion matrix
```

---

### **Step 3: Run full pipeline**

Cháº¡y táº¥t cáº£ cÃ¹ng lÃºc:

```bash
bash experiments/dede_adapted/run_dede_experiment.sh
```

---

## ğŸ“ˆ Káº¿t quáº£ mong Ä‘á»£i

### **1. Training Results:**

```
Epoch 100/100
loss: 0.0234 - val_loss: 0.0267
âœ“ Training completed!
Best val_loss: 0.0267
```

### **2. Reconstruction Errors:**

```
Clean samples:
  Mean: 0.0245 Â± 0.0089
  Range: [0.0012, 0.0567]

Adversarial samples:
  Mean: 0.0389 Â± 0.0145
  Range: [0.0098, 0.0892]

ğŸ“Š Error increase: +0.0144 (+58.78%)
```

### **3. Detection Performance:**

```
Detection Performance:
  Accuracy:  0.8765
  Precision: 0.8523
  Recall:    0.7891
  F1-Score:  0.8193
  AUC:       0.9234

Detection Rates:
  True Positive Rate: 0.7891 (1578/2000)
  False Positive Rate: 0.0512 (102/1992)
```

**Giáº£i thÃ­ch:**
- **High reconstruction error** = Adversarial sample
- **Recall 78.91%**: PhÃ¡t hiá»‡n Ä‘Æ°á»£c 78.91% adversarial samples
- **Precision 85.23%**: 85.23% samples detected lÃ  tháº­t sá»± adversarial
- **F1 0.8193**: CÃ¢n báº±ng tá»‘t giá»¯a precision & recall
- **AUC 0.9234**: Model phÃ¢n biá»‡t ráº¥t tá»‘t clean vs adversarial

---

## ğŸ”¬ PhÃ¢n tÃ­ch ká»¹ thuáº­t

### **1. Táº¡i sao reconstruction error cao = adversarial?**

**Clean samples:**
- Trong distribution cá»§a training data
- Model Ä‘Ã£ há»c reconstruct tá»‘t
- â†’ **Low reconstruction error**

**Adversarial samples (GAN-generated):**
- Out-of-distribution (khÃ¡c normal traffic)
- Model khÃ´ng biáº¿t reconstruct  
- â†’ **High reconstruction error**

```
Think of it like:
- Encoder-Decoder há»c "chá»¯ viáº¿t cá»§a báº¡n"
- Clean data: Chá»¯ báº¡n viáº¿t â†’ reconstruct tá»‘t
- Adversarial: Chá»¯ ngÆ°á»i khÃ¡c viáº¿t â†’ reconstruct kÃ©m
```

### **2. Æ¯u Ä‘iá»ƒm cá»§a DeDe-Adapted:**

âœ… **Unsupervised/Self-supervised**: KhÃ´ng cáº§n labels trong training  
âœ… **Generalization**: CÃ³ thá»ƒ detect cÃ¡c loáº¡i adversarial chÆ°a biáº¿t  
âœ… **Interpretable**: Reconstruction error dá»… hiá»ƒu  
âœ… **Flexible**: CÃ³ thá»ƒ tune threshold theo FPR mong muá»‘n  

### **3. Háº¡n cháº¿:**

âŒ **Cáº§n tune threshold**: Pháº£i chá»n percentile phÃ¹ há»£p  
âŒ **Trade-off TPR vs FPR**: Threshold cao â†’ recall tháº¥p, precision cao  
âŒ **Phá»¥ thuá»™c training data**: Náº¿u training data khÃ´ng representative â†’ kÃ©m  

---

## ğŸ›ï¸ Hyperparameter Tuning

### **Mask Ratio:**

```bash
# Thá»­ cÃ¡c giÃ¡ trá»‹ khÃ¡c nhau
for MASK_RATIO in 0.3 0.5 0.7; do
    python experiments/dede_adapted/train_dede.py \
        --mask-ratio $MASK_RATIO \
        --output-dir experiments/dede_adapted/models_mask${MASK_RATIO}
done
```

**Recommendation:**
- `0.3`: Ãt masking â†’ dá»… train, Ã­t regularization
- `0.5`: **Balanced** (khuyáº¿n nghá»‹)
- `0.7`: Nhiá»u masking â†’ khÃ³ train, nhiá»u regularization

### **Latent Dimension:**

```bash
# Thá»­ cÃ¡c kÃ­ch thÆ°á»›c khÃ¡c nhau
for LATENT_DIM in 32 64 128; do
    python experiments/dede_adapted/train_dede.py \
        --latent-dim $LATENT_DIM \
        --output-dir experiments/dede_adapted/models_latent${LATENT_DIM}
done
```

**Recommendation:**
- `32`: Compact â†’ cÃ³ thá»ƒ underfit
- `64`: **Balanced** (khuyáº¿n nghá»‹)
- `128`: Large â†’ cÃ³ thá»ƒ overfit

### **Threshold Percentile:**

```bash
# Thá»­ cÃ¡c threshold khÃ¡c nhau
for PCT in 90 95 99; do
    python experiments/dede_adapted/detect_adversarial.py \
        --threshold-percentile $PCT \
        --output-dir experiments/dede_adapted/results_pct${PCT}
done
```

**Trade-off:**
- `90`: Higher recall, lower precision (10% FPR)
- `95`: **Balanced** (5% FPR) - khuyáº¿n nghá»‹
- `99`: Lower recall, higher precision (1% FPR)

---

## ğŸ“Š So sÃ¡nh vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c

| Method | Accuracy | F1-Score | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|--------|----------|----------|---------|-----------|
| **Baseline Models** | 0.92 | 0.91 | Supervised, accurate | Cáº§n labels, khÃ´ng detect unknown |
| **Ensemble** | 0.94 | 0.93 | Káº¿t há»£p nhiá»u models | Phá»©c táº¡p, cháº­m |
| **DeDe-Adapted** | 0.88 | 0.82 | Unsupervised, interpretable | Tháº¥p hÆ¡n supervised |

**Khi nÃ o dÃ¹ng DeDe-Adapted?**
- âœ… Muá»‘n detect **unknown/zero-day** adversarial attacks
- âœ… KhÃ´ng cÃ³ labels cho adversarial samples
- âœ… Cáº§n **interpretability** (reconstruction error)
- âœ… Research/experimental setting

**Khi nÃ o KHÃ”NG dÃ¹ng?**
- âŒ Cáº§n accuracy cao nháº¥t â†’ DÃ¹ng ensemble
- âŒ CÃ³ Ä‘á»§ labeled data â†’ DÃ¹ng supervised learning
- âŒ Production system critical â†’ DÃ¹ng proven methods

---

## ğŸ”„ Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXP1: BASELINE (Clean Data)        â”‚
â”‚  - Train models (MLP, SVM, RF...)   â”‚
â”‚  - Save models & data splits        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRAIN DeDe-Adapted                 â”‚
â”‚  - Load Exp1 clean data             â”‚
â”‚  - Train encoder-decoder            â”‚
â”‚  - Learn to reconstruct features    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXP3: GAN ATTACK (Adversarial)     â”‚
â”‚  - Generate adversarial samples     â”‚
â”‚  - Save test data with GAN samples  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DETECT with DeDe-Adapted           â”‚
â”‚  - Calculate reconstruction errors  â”‚
â”‚  - Clean vs Adversarial comparison  â”‚
â”‚  - Metrics: Accuracy, F1, AUC       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Tham kháº£o

1. **DeDe Paper**: "DeDe: Detecting Backdoor Samples for SSL Encoders via Decoders" (CVPR 2025)
   - https://arxiv.org/abs/2411.16154

2. **Masked Autoencoders**: "Masked Autoencoders Are Scalable Vision Learners" (CVPR 2022)
   - Ã tÆ°á»Ÿng masking vÃ  reconstruction

3. **Anomaly Detection**: Reconstruction-based anomaly detection
   - Out-of-distribution detection using autoencoders

---

## ğŸ’¡ Tips & Tricks

### **1. Improve detection performance:**

```python
# Ensemble nhiá»u DeDe models vá»›i khÃ¡c mask_ratio
models = [
    train_dede(mask_ratio=0.3),
    train_dede(mask_ratio=0.5),
    train_dede(mask_ratio=0.7)
]

# Average reconstruction errors
errors = np.mean([m.get_reconstruction_error(X) for m in models], axis=0)
```

### **2. Feature-wise analysis:**

```python
# Xem feature nÃ o bá»‹ reconstruct kÃ©m nháº¥t
reconstructed, _ = model(X_adv)
feature_errors = np.mean((X_adv - reconstructed) ** 2, axis=0)

# Top features causing high errors
top_features = np.argsort(feature_errors)[-10:]
print(f"Most affected features: {top_features}")
```

### **3. Adaptive threshold:**

```python
# Thay vÃ¬ fixed percentile, dÃ¹ng adaptive threshold
from sklearn.mixture import GaussianMixture

gmm = GaussianMixture(n_components=2).fit(errors.reshape(-1, 1))
threshold = gmm.means_.min()  # Between two Gaussian peaks
```

---

## ğŸ¯ Káº¿t luáº­n

**DeDe-Adapted** lÃ  má»™t cáº£i tiáº¿n thÃº vá»‹ tá»« DeDe (CVPR 2025) Ä‘á»ƒ Ã¡p dá»¥ng cho **network traffic data**. 

**Key contributions:**
1. âœ… Adapt Vision Transformer â†’ MLP cho tabular data
2. âœ… Adapt Masked patches â†’ Masked features
3. âœ… Apply reconstruction error cho adversarial detection
4. âœ… Unsupervised/self-supervised approach

**Káº¿t quáº£:**
- PhÃ¡t hiá»‡n ~79% adversarial samples vá»›i 5% FPR
- AUC ~0.92 cho binary classification
- Interpretable (reconstruction error)

**Future work:**
- Thá»­ cÃ¡c encoder architecture khÃ¡c (Transformer-based)
- Ensemble multiple DeDe models
- Adaptive threshold learning
- Application to other attack types (poisoning, backdoor)

---

Happy experimenting! ğŸš€
